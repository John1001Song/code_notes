{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://localhost:8888/notebooks/Documents/ML-jsong32/class/Mar%2027%20Decision%20Tree.ipynb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "col = X.iloc[:, -1]\n",
    "le = LabelEncoder()\n",
    "le.fit(col)\n",
    "encoded_column = le.transform(col)\n",
    "encoded_column\n",
    "X['color'] = encoded_column\n",
    "\n",
    "# should use 1-hot encoding \n",
    "# R G B\n",
    "# 1 0 0\n",
    "# 0 0 1\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date to Unix Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://localhost:8888/notebooks/Documents/ML-jsong32/data_challenge/Flight%20Delays.ipynb\n",
    "\n",
    "index = pd.DatetimeIndex(df.FL_DATE)\n",
    "index\n",
    "\n",
    "df.FL_DATE = index.astype(np.int64)//10**9 # to seconds\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join (left, right, outer), merge, etc  \n",
    "https://www.datacamp.com/community/tutorials/joining-dataframes-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with built in cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "    \n",
    ">>> from sklearn.datasets import load_iris\n",
    ">>> from sklearn.linear_model import LogisticRegressionCV\n",
    ">>> X, y = load_iris(return_X_y=True)\n",
    ">>> clf = LogisticRegressionCV(cv=5, random_state=0,\n",
    "...                            multi_class='multinomial').fit(X, y)\n",
    ">>> clf.predict(X[:2, :])\n",
    "array([0, 0])\n",
    ">>> clf.predict_proba(X[:2, :]).shape\n",
    "(2, 3)\n",
    ">>> clf.score(X, y) \n",
    "0.98..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traditional logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    \n",
    ">>> from sklearn.datasets import load_iris\n",
    ">>> from sklearn.linear_model import LogisticRegression\n",
    ">>> X, y = load_iris(return_X_y=True)\n",
    ">>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "...                          multi_class='multinomial').fit(X, y)\n",
    ">>> clf.predict(X[:2, :])\n",
    "array([0, 0])\n",
    ">>> clf.predict_proba(X[:2, :]) \n",
    "array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
    "       [9.7...e-01, 2.8...e-02, ...e-08]])\n",
    ">>> clf.score(X, y)\n",
    "0.97..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "    \n",
    ">>> from sklearn import datasets\n",
    ">>> iris = datasets.load_iris()\n",
    ">>> from sklearn.naive_bayes import GaussianNB\n",
    ">>> gnb = GaussianNB()\n",
    ">>> y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    ">>> print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "...       % (iris.data.shape[0],(iris.target != y_pred).sum()))\n",
    "Number of mislabeled points out of a total 150 points : 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    \n",
    ">>> import numpy as np\n",
    ">>> from sklearn import linear_model\n",
    ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    ">>> Y = np.array([1, 1, 2, 2])\n",
    ">>> clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    ">>> clf.fit(X, Y)\n",
    "... \n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
    "       n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
    "       random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
    "       verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    ">>> from sklearn.neighbors import NearestNeighbors\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    ">>> nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    ">>> distances, indices = nbrs.kneighbors(X)\n",
    ">>> indices                                           \n",
    "array([[0, 1],\n",
    "       [1, 0],\n",
    "       [2, 1],\n",
    "       [3, 4],\n",
    "       [4, 3],\n",
    "       [5, 4]]...)\n",
    ">>> distances\n",
    "array([[0.        , 1.        ],\n",
    "       [0.        , 1.        ],\n",
    "       [0.        , 1.41421356],\n",
    "       [0.        , 1.        ],\n",
    "       [0.        , 1.        ],\n",
    "       [0.        , 1.41421356]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "    \n",
    ">>> X = [[0], [1], [2], [3]]\n",
    ">>> y = [0, 0, 1, 1]\n",
    ">>> from sklearn.neighbors import KNeighborsClassifier\n",
    ">>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
    ">>> neigh.fit(X, y) \n",
    "KNeighborsClassifier(...)\n",
    ">>> print(neigh.predict([[1.1]]))\n",
    "[0]\n",
    ">>> print(neigh.predict_proba([[0.9]]))\n",
    "[[0.66666667 0.33333333]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "    \n",
    ">>> from sklearn.ensemble import RandomForestClassifier\n",
    ">>> from sklearn.datasets import make_classification\n",
    "\n",
    ">>> X, y = make_classification(n_samples=1000, n_features=4,\n",
    "...                            n_informative=2, n_redundant=0,\n",
    "...                            random_state=0, shuffle=False)\n",
    ">>> clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "...                              random_state=0)\n",
    ">>> clf.fit(X, y)  \n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    ">>> print(clf.feature_importances_)\n",
    "[0.14205973 0.76664038 0.0282433  0.06305659]\n",
    ">>> print(clf.predict([[0, 0, 0, 0]]))\n",
    "[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "    \n",
    ">>> from sklearn import svm\n",
    ">>> X = [[0, 0], [1, 1]]\n",
    ">>> y = [0, 1]\n",
    ">>> clf = svm.SVC(gamma='scale')\n",
    ">>> clf.fit(X, y)  \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "After being fitted, the model can then be used to predict new values:\n",
    "\n",
    ">>>\n",
    ">>> clf.predict([[2., 2.]])\n",
    "array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "    \n",
    ">>> from sklearn.metrics import accuracy_score\n",
    ">>> y_pred = [0, 2, 1, 3]\n",
    ">>> y_true = [0, 1, 2, 3]\n",
    ">>> accuracy_score(y_true, y_pred)\n",
    "0.5\n",
    ">>> accuracy_score(y_true, y_pred, normalize=False)\n",
    "2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "    \n",
    ">>> from sklearn.model_selection import cross_val_score\n",
    ">>> clf = svm.SVC(kernel='linear', C=1)\n",
    ">>> scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    ">>> scores                                              \n",
    "array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score\n",
    "    \n",
    ">>> from sklearn import datasets, linear_model\n",
    ">>> from sklearn.model_selection import cross_val_score\n",
    ">>> diabetes = datasets.load_diabetes()\n",
    ">>> X = diabetes.data[:150]\n",
    ">>> y = diabetes.target[:150]\n",
    ">>> lasso = linear_model.Lasso()\n",
    ">>> print(cross_val_score(lasso, X, y, cv=3))  \n",
    "[0.33150734 0.08022311 0.03531764]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can return train scores, test scores, and estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    \n",
    "    \n",
    ">>> from sklearn import datasets, linear_model\n",
    ">>> from sklearn.model_selection import cross_validate\n",
    ">>> from sklearn.metrics.scorer import make_scorer\n",
    ">>> from sklearn.metrics import confusion_matrix\n",
    ">>> from sklearn.svm import LinearSVC\n",
    ">>> diabetes = datasets.load_diabetes()\n",
    ">>> X = diabetes.data[:150]\n",
    ">>> y = diabetes.target[:150]\n",
    ">>> lasso = linear_model.Lasso()\n",
    "\n",
    ">>> cv_results = cross_validate(lasso, X, y, cv=3)\n",
    ">>> sorted(cv_results.keys())                         \n",
    "['fit_time', 'score_time', 'test_score']\n",
    ">>> cv_results['test_score']    \n",
    "array([0.33150734, 0.08022311, 0.03531764])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "    \n",
    ">>> import numpy as np\n",
    ">>> from sklearn.model_selection import KFold\n",
    ">>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    ">>> y = np.array([1, 2, 3, 4])\n",
    ">>> kf = KFold(n_splits=2)\n",
    ">>> kf.get_n_splits(X)\n",
    "2\n",
    ">>> print(kf)  \n",
    "KFold(n_splits=2, random_state=None, shuffle=False)\n",
    ">>> for train_index, test_index in kf.split(X):\n",
    "...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "...    X_train, X_test = X[train_index], X[test_index]\n",
    "...    y_train, y_test = y[train_index], y[test_index]\n",
    "TRAIN: [2 3] TEST: [0 1]\n",
    "TRAIN: [0 1] TEST: [2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run python by nohup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup python bgservice.py &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
